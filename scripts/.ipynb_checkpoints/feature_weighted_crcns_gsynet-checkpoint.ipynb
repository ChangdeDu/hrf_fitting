{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glue gsynet (predictive coding network) to crcns data with feature-weighted rf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version_number =  '0p1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr\n",
    "from hrf_fitting.src.feature_weighted_rf_models import make_rf_table,receptive_fields, model_space, prediction_menu,bigmult\n",
    "from hrf_fitting.src.feature_weighted_rf_models import train_fwrf_model\n",
    "from hrf_fitting.src.gabor_feature_dictionaries import gabor_feature_maps\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Load crcns-gsynet feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##known stimulus parameters\n",
    "Ttrn = 1750\n",
    "Tval = 120\n",
    "\n",
    "##don't use these\n",
    "junk_keys = ['__header__', '__globals__', '__version__', 'fc6', 'fc7', 'fc8','prob']\n",
    "\n",
    "##this is > 8GB\n",
    "deepnet_trn_feature_dict = loadmat('/media/tnaselar/Data/predicive_coding_1/pc1_vim-1_trn_response.mat')\n",
    "##it contains some key/value pairs we don't want\n",
    "\n",
    "deepnet_trn_feature_dict = {key: value.astype('float32') for key, value in deepnet_trn_feature_dict.items() if key not in junk_keys}\n",
    "print deepnet_trn_feature_dict.keys()\n",
    "\n",
    "##much smaller\n",
    "deepnet_val_feature_dict = loadmat('/media/tnaselar/Data/predicive_coding_1/pc1_vim-1_val_response.mat')\n",
    "##it contains some key/value pairs we don't want\n",
    "deepnet_val_feature_dict = {key: value.astype('float32') for key, value in deepnet_val_feature_dict.items() if key not in junk_keys}\n",
    "print deepnet_val_feature_dict.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for these inputs we need to put the feature-depth upfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for kk in deepnet_trn_feature_dict.keys():\n",
    "    deepnet_trn_feature_dict[kk] = np.swapaxes(deepnet_trn_feature_dict[kk][:,np.newaxis,:,:,:], 4,1).squeeze()\n",
    "    \n",
    "for kk in deepnet_val_feature_dict.keys():\n",
    "    deepnet_val_feature_dict[kk] = np.swapaxes(deepnet_val_feature_dict[kk][:,np.newaxis,:,:,:], 4,1).squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: receptive fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deg_per_stimulus = 20\n",
    "deg_per_radius = (.75, 8., 6) ##rf sizes in degrees (smallest, largest, number of sizes)\n",
    "spacing = 1.5 ##spacing between rf's in degrees\n",
    "rf = receptive_fields(deg_per_stimulus,deg_per_radius,spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.rf_table['deg_per_radius'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'G = number of rf models = %d' %(rf.rf_table.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### instantiate model space object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print deepnet_trn_feature_dict['p1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##construct the model space\n",
    "ms = model_space(deepnet_trn_feature_dict, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms.feature_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deepnet_trn_feature_dict['p1'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### construct training/validation model space tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##training data\n",
    "trn_mst = ms.construct_model_space_tensor(deepnet_trn_feature_dict,normalize=False)\n",
    "\n",
    "##normalize and save normalization constants\n",
    "trn_mst = ms.normalize_model_space_tensor(trn_mst, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##validation data\n",
    "val_mst = ms.construct_model_space_tensor(deepnet_val_feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del deepnet_trn_feature_dict\n",
    "del deepnet_val_feature_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: load and package crcns voxel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voxel_file = '/media/tnaselar/Data/crcns_datasets/vim-1/EstimatedResponses.mat'\n",
    "crcns_voxel_data = h5py.File(voxel_file,'r')\n",
    "crcns_voxel_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenate val/trn and remove nans\n",
    "A few thousand voxels have missing obersvations, remove them because even one nan will infect gradient for every voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject = 'S1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##concatenate \n",
    "voxel_data = np.concatenate((crcns_voxel_data['dataVal'+subject],crcns_voxel_data['dataTrn'+subject]),axis=0).astype('float32')\n",
    "V_orig = voxel_data.shape[1]\n",
    "\n",
    "\n",
    "no_nan = np.isnan(voxel_data).sum(axis=0) == 0 ##<<only pulled voxels with nans in training data, should pull if nans in val data too.\n",
    "voxel_data = voxel_data[:,no_nan]\n",
    "print voxel_data.shape\n",
    "V = voxel_data.shape[1] ##should be 25915\n",
    "vox_idx = np.arange(0,V_orig)[no_nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print '++++++++SUBJECT: %s+++++++++++' %(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print vox_idx.shape\n",
    "plt.plot(vox_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crcns_voxel_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get training/validation views on voxel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = Tval+Ttrn\n",
    "nvox = V\n",
    "trnIdx = np.arange(Tval,T)\n",
    "valIdx = np.arange(0,Tval)\n",
    "trn_voxel_data = voxel_data[trnIdx,0:nvox]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms.receptive_fields.G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: run that shit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize the feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_feature_weights = 'zeros'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fvl,ffw,frf,beh = train_fwrf_model(trn_mst,\n",
    "                 trn_voxel_data,\n",
    "                 initial_feature_weights = initial_feature_weights,\n",
    "                 voxel_binsize = nvox,\n",
    "                 rf_grid_binsize=10,\n",
    "                 learning_rate=10**(-7.0),\n",
    "                 max_iters = 300,\n",
    "                 early_stop_fraction=0.2,\n",
    "                 report_every = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction accuracy for all voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##grab validation data\n",
    "val_voxel_data = voxel_data[valIdx,0:nvox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##generate predictions\n",
    "# pred = prediction_menu(val_mst, ffw[np.newaxis,:,:], rf_indices = frf) ##<<too big, choked. \n",
    "\n",
    "\n",
    "##generate predictions one voxel at a time\n",
    "pred = np.zeros((Tval,nvox))\n",
    "for v in range(nvox):  ##FIXED ! ?<<some kind of bug in training function, last voxel getting skipped...th\n",
    "    pred[:,v] = np.squeeze(bigmult(val_mst[np.newaxis,frf[v],:,:],\n",
    "                                   ffw[np.newaxis,:,v, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##get correlation = prediction accuracy\n",
    "val_cc = np.zeros(nvox) \n",
    "for v in range(nvox): \n",
    "    cc = pearsonr(val_voxel_data[:,v],pred[:,v])\n",
    "    val_cc[v]=cc[0]\n",
    "val_cc = np.nan_to_num(val_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save model and val_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "saving_place = '/media/tnaselar/Data/deepnet_vim-1/feature_weighted_models/'\n",
    "saving_file = 'model_space_'+version_number+'.p'\n",
    "ms.optimal_feature_weights = ffw\n",
    "ms.optimal_rf_model = frf\n",
    "ms.val_cc = val_cc\n",
    "pickle.dump(ms, open( join(saving_place, saving_file), \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram of val_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##histogram of prediction accuracy, all voxels\n",
    "_=plt.hist(val_cc,100)\n",
    "plt.yscale('log')\n",
    "plt.ylim([10**0, 10**3])\n",
    "plt.xlim([-.4, 0.9])\n",
    "\n",
    "np.sum(map(lambda x: x > 0.2, val_cc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss histories, all voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.plot(beh-beh[0,:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### view loss history for a few voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.plot(beh[:,slice(0,-1,1200)]-beh[0,slice(0,-1,1200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##loss in \"final_validation_loss\" = last point of \"best_error_history\"\n",
    "print np.min(beh[:,-2])\n",
    "print fvl[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diff between first and last point of loss history, all voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(np.nan_to_num(beh[0,:]-np.min(beh,axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.hist(np.nan_to_num(beh[0,:]-np.min(beh,axis=0)),100)\n",
    "plt.yscale('log')\n",
    "plt.xlim([0, 140])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: model analysis and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram of rf models selected for each voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_=plt.hist(frf,ms.receptive_fields.G)\n",
    "plt.xlabel('smaller-->bigger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sum of all selected rfs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.sum(ms.receptive_fields.make_rf_stack(64, min_pix_per_radius=1)[frf,:,:], axis=0), cmap='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### area-wise prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##get position information. need to re-open file\n",
    "voxel_file = '/media/tnaselar/Data/crcns_datasets/vim-1/EstimatedResponses.mat'\n",
    "crcns_voxel_data = h5py.File(voxel_file,'r')\n",
    "\n",
    "vox_position = crcns_voxel_data['voxIdxS1'][0,no_nan]  ##index into a 64 x 64 x 18 volume (matlab-style raveling)\n",
    "\n",
    "##get the indices for visual areas\n",
    "roi_indicator = crcns_voxel_data['roiS1'][0, no_nan]\n",
    "roi_names = ['other', 'v1', 'v2', 'v3', 'v3A', 'v3B', 'v4', 'LO']\n",
    "\n",
    "crcns_voxel_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##area-wise prediction accuracy\n",
    "areawise_accuracy = []\n",
    "for ii,roi in enumerate(roi_names):\n",
    "    voxels_in_roi = roi_indicator == ii\n",
    "    areawise_accuracy.append(np.array(val_cc)[voxels_in_roi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.boxplot(areawise_accuracy,labels = roi_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_rois = len(roi_names)\n",
    "fig = plt.figure(figsize = (4,12))\n",
    "for ii,roi in enumerate(roi_names):\n",
    "    plt.subplot(n_rois,1,ii+1)\n",
    "    plt.hist(areawise_accuracy[ii],100)\n",
    "    plt.yscale('log')\n",
    "    plt.xlim([-0.4, 0.85])\n",
    "    plt.ylim([0, 10**3])\n",
    "    plt.title(roi)\n",
    "plt.tight_layout()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### area-wise rf size vs. eccentricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## construct data table of rfs--indices will now be voxels\n",
    "frf_sizes = ms.receptive_fields.rf_table.loc[frf,'deg_per_radius'].values\n",
    "frf_eccentricities = ms.receptive_fields.rf_table.loc[frf, ['x_deg','y_deg']].apply(lambda row: np.sqrt(row['x_deg']**2+row['y_deg']**2),axis=1).values\n",
    "named_voxels = [roi_names[int(v)] for v in roi_indicator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_table = pd.DataFrame(data=list(frf_sizes), columns=['roi_size'])\n",
    "model_table['eccentricity'] = frf_eccentricities\n",
    "model_table['area'] = named_voxels\n",
    "model_table['valcc'] = val_cc\n",
    "\n",
    "model_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_thresh = 0.25\n",
    "size_means = {}\n",
    "size_stds = {}\n",
    "area_eccs = {}\n",
    "for roi in roi_names:\n",
    "    area_stats = model_table.loc[(model_table['area']==roi) & (model_table['valcc'] > val_thresh),['roi_size', 'eccentricity']]\n",
    "    ecc_grp = area_stats.groupby(by='eccentricity')\n",
    "    size_means[roi] = []\n",
    "    size_stds[roi] = []\n",
    "    area_eccs[roi] = []\n",
    "    for name,grp in ecc_grp:\n",
    "        area_eccs[roi].append(name)\n",
    "        size_means[roi].append(grp.roi_size.mean())\n",
    "        size_stds[roi].append(grp.roi_size.std())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roi_colors = ['black', 'r', 'salmon', 'coral', 'darkslategray', 'teal','orangered', 'indigo' ]\n",
    "ecc = np.sort(np.unique(model_table['eccentricity']))\n",
    "line_list = []\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for r,roi in enumerate(roi_names):\n",
    "    plt.plot(area_eccs[roi],size_means[roi], 'o', color=roi_colors[r])\n",
    "    p = np.polyfit(area_eccs[roi],size_means[roi],1)\n",
    "    l, = plt.plot(area_eccs[roi], np.polyval(p,area_eccs[roi]), color=roi_colors[r], label=roi, linewidth=4)\n",
    "    line_list.append(l)\n",
    "    \n",
    "plt.legend(loc='upper left', ncol = 4)    \n",
    "# plt.axis('equal')\n",
    "plt.xlim([0,14])\n",
    "plt.ylim([0,8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### layer x area weight distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layer_names = ['conv1', 'conv2', 'conv3', 'conv4', 'conv5']\n",
    "weights = np.zeros(( len(ms.feature_depth.keys()), len(roi_names),))\n",
    "\n",
    "for ii,roi in enumerate(roi_names):\n",
    "    voxels_in_roi = roi_indicator == ii\n",
    "    layer_cnt = 0\n",
    "    for layer in layer_names:\n",
    "        idx = ms.feature_indices[layer]\n",
    "        weights[layer_cnt,ii] = np.mean(ffw[idx,:][:,voxels_in_roi])\n",
    "        layer_cnt += 1\n",
    "\n",
    "plt.pcolor(weights, cmap='hot')\n",
    "plt.ylabel(layer_names)\n",
    "plt.xlabel(roi_names)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,10))\n",
    "for ii,roi in enumerate(roi_names):\n",
    "    _=plt.plot([1,2,3,4,5],weights[:,ii],'o-',label=roi, color = roi_colors[ii], linewidth=3)\n",
    "plt.legend(loc='lower right', ncol=4)\n",
    "plt.xticks([1,2,3,4,5])\n",
    "plt.xlabel('conv layer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
