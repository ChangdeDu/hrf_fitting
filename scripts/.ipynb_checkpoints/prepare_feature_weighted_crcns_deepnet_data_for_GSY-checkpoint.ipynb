{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load up and package data for a model run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version_number =  '0p2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr\n",
    "from hrf_fitting.src.feature_weighted_rf_models import make_rf_table,receptive_fields, model_space, prediction_menu,bigmult\n",
    "from hrf_fitting.src.feature_weighted_rf_models import train_fwrf_model\n",
    "from hrf_fitting.src.gabor_feature_dictionaries import gabor_feature_maps\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: load up pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saving_place = '/media/tnaselar/Data/deepnet_vim-1/feature_weighted_models/'\n",
    "saving_file = 'model_space_'+version_number+'.p'\n",
    "\n",
    "ms = pickle.load(open( join(saving_place, saving_file), \"r\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Load crcns feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##known stimulus parameters\n",
    "Ttrn = 1750\n",
    "Tval = 120\n",
    "\n",
    "##don't use these\n",
    "junk_keys = ['__header__', '__globals__', '__version__', 'fc6', 'fc7', 'fc8','prob']\n",
    "\n",
    "##this is > 8GB\n",
    "deepnet_trn_feature_dict = loadmat('/media/tnaselar/Data/deepnet_vim-1/vim-1_trn_response.mat')\n",
    "##it contains some key/value pairs we don't want\n",
    "\n",
    "deepnet_trn_feature_dict = {key: value.astype('float32') for key, value in deepnet_trn_feature_dict.items() if key not in junk_keys}\n",
    "print deepnet_trn_feature_dict.keys()\n",
    "\n",
    "##much smaller\n",
    "deepnet_val_feature_dict = loadmat('/media/tnaselar/Data/deepnet_vim-1/vim-1_val_response.mat')\n",
    "##it contains some key/value pairs we don't want\n",
    "deepnet_val_feature_dict = {key: value.astype('float32') for key, value in deepnet_val_feature_dict.items() if key not in junk_keys}\n",
    "print deepnet_val_feature_dict.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: receptive fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deg_per_stimulus = 20\n",
    "deg_per_radius = (.75, 8., 6) ##rf sizes in degrees (smallest, largest, number of sizes)\n",
    "spacing = 1.5 ##spacing between rf's in degrees\n",
    "rf = receptive_fields(deg_per_stimulus,deg_per_radius,spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.rf_table['deg_per_radius'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'G = number of rf models = %d' %(rf.rf_table.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### construct training/validation model space tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##training data\n",
    "trn_mst = ms.construct_model_space_tensor(deepnet_trn_feature_dict,normalize=False)\n",
    "\n",
    "##normalize and save normalization constants\n",
    "trn_mst = ms.normalize_model_space_tensor(trn_mst, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##validation data\n",
    "val_mst = ms.construct_model_space_tensor(deepnet_val_feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del deepnet_trn_feature_dict\n",
    "del deepnet_val_feature_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: load and package crcns voxel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voxel_file = '/media/tnaselar/Data/crcns_datasets/vim-1/EstimatedResponses.mat'\n",
    "crcns_voxel_data = h5py.File(voxel_file,'r')\n",
    "crcns_voxel_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenate val/trn and remove nans\n",
    "A few thousand voxels have missing obersvations, remove them because even one nan will infect gradient for every voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##concatenate \n",
    "voxel_data = np.concatenate((crcns_voxel_data['dataValS1'],crcns_voxel_data['dataTrnS1']),axis=0).astype('float32')\n",
    "V_orig = voxel_data.shape[1]\n",
    "\n",
    "\n",
    "no_nan = np.isnan(voxel_data).sum(axis=0) == 0 ##<<only pulled voxels with nans in training data, should pull if nans in val data too.\n",
    "voxel_data = voxel_data[:,no_nan]\n",
    "print voxel_data.shape\n",
    "V = voxel_data.shape[1] ##should be 25915\n",
    "vox_idx = np.arange(0,V_orig)[no_nan]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print vox_idx.shape\n",
    "plt.plot(vox_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crcns_voxel_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get training/validation views on voxel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = Tval+Ttrn\n",
    "nvox= V\n",
    "trnIdx = np.arange(Tval,T)\n",
    "valIdx = np.arange(0,Tval)\n",
    "trn_voxel_data = voxel_data[trnIdx,0:nvox]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction accuracy for all voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##grab validation data\n",
    "val_voxel_data = voxel_data[valIdx,0:nvox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##generate predictions\n",
    "# pred = prediction_menu(val_mst, ffw[np.newaxis,:,:], rf_indices = frf) ##<<too big, choked. \n",
    "\n",
    "\n",
    "##generate predictions one voxel at a time\n",
    "pred = np.zeros((Tval,nvox))\n",
    "for v in range(nvox):  ##FIXED ! ?<<some kind of bug in training function, last voxel getting skipped...th\n",
    "    pred[:,v] = np.squeeze(bigmult(val_mst[np.newaxis,frf[v],:,:],\n",
    "                                   ffw[np.newaxis,:,v, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##get correlation = prediction accuracy\n",
    "val_cc = []  \n",
    "for v in range(nvox): \n",
    "    cc = pearsonr(val_voxel_data[:,v],pred[:,v])\n",
    "    if not np.isnan(cc[0]):\n",
    "        val_cc.append(cc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##histogram of prediction accuracy, all voxels\n",
    "_=plt.hist(val_cc,100)\n",
    "plt.yscale('log')\n",
    "plt.ylim([10**0, 10**3])\n",
    "plt.xlim([-.4, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(map(lambda x: x > 0.2, val_cc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### area-wise prediction accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##get position information. need to re-open file\n",
    "voxel_file = '/media/tnaselar/Data/crcns_datasets/vim-1/EstimatedResponses.mat'\n",
    "crcns_voxel_data = h5py.File(voxel_file,'r')\n",
    "\n",
    "vox_position = crcns_voxel_data['voxIdxS1'][0,no_nan]  ##index into a 64 x 64 x 18 volume (matlab-style raveling)\n",
    "\n",
    "##get the indices for visual areas\n",
    "roi_indicator = crcns_voxel_data['roiS1'][0, no_nan]\n",
    "roi_names = ['other', 'v1', 'v2', 'v3', 'v3A', 'v3B', 'v4', 'LO']\n",
    "\n",
    "crcns_voxel_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##area-wise prediction accuracy\n",
    "areawise_accuracy = []\n",
    "for ii,roi in enumerate(roi_names):\n",
    "    voxels_in_roi = roi_indicator == ii\n",
    "    areawise_accuracy.append(np.array(val_cc)[voxels_in_roi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.boxplot(areawise_accuracy,labels = roi_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_rois = len(roi_names)\n",
    "fig = plt.figure(figsize = (4,12))\n",
    "for ii,roi in enumerate(roi_names):\n",
    "    plt.subplot(n_rois,1,ii+1)\n",
    "    plt.hist(areawise_accuracy[ii],100)\n",
    "    plt.yscale('log')\n",
    "    plt.xlim([-0.4, 0.85])\n",
    "    plt.ylim([0, 10**3])\n",
    "    plt.title(roi)\n",
    "plt.tight_layout()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
