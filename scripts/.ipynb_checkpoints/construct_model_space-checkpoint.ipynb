{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from theano import tensor as tnsr\n",
    "from theano import function, scan\n",
    "from time import time\n",
    "from scipy.signal import convolve2d as conv2d\n",
    "from hrf_fitting.src.features import make_gaussian, construct_placement_grid\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "from hrf_fitting.src.feature_weighted_rf_models import apply_rf_to_feature_maps, bigmult, compute_grad,sq_diff_func\n",
    "from hrf_fitting.src.features import make_complex_gabor as gaborme\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr\n",
    "from hrf_fitting.src.features import compute_grid_corners, compute_grid_spacing, construct_placement_grid\n",
    "from itertools import product\n",
    "from warnings import warn\n",
    "\n",
    "%matplotlib inline  \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_rf_table(deg_per_stim,deg_per_radius,spacing,pix_per_stim = None):\n",
    "    '''\n",
    "    here is the machinery for setting up grid of rfs\n",
    "    includes machinery for downsampling to different pixel resolutions\n",
    "    \n",
    "    make_rf_table(deg_per_stim,deg_per_radius,spacing,pix_per_stim = None)\n",
    "\n",
    "    deg_per_stim   ~ scalar, determined by experiment\n",
    "    deg_per_radius ~ (min_rad, max_rad, num_rad) specify the range rf sizes\n",
    "    spacing        ~ scalar, spacing between rfs in deg\n",
    "    pix_per_stim   ~ integer, default = None. If defined, add columns to rf_table with rf dimensions in pixels.\n",
    "    returns\n",
    "        rf_table   ~ pandas dataframe, each row an rf with columns 'deg_per_radius', 'x_deg','y_deg'\n",
    "                     all units in deg. relative to origin of feature map = (0,0)\n",
    "                     If pix_per_stim given, add columns 'pix_per_radius' and 'x_pix', 'y_pix' \n",
    "    '''\n",
    "    n_sizes = deg_per_radius[2]\n",
    "    rf_radii_deg = np.linspace(deg_per_radius[0],deg_per_radius[1],num=n_sizes,endpoint=True)\n",
    "    \n",
    "    corners = compute_grid_corners(deg_per_stim, 0, boundary_condition=0) ##<<puts center of stim at (0,0)\n",
    "    x_deg,y_deg = construct_placement_grid(corners,spacing)\n",
    "    \n",
    "    \n",
    "    number_of_rfs = x_deg.ravel().size*rf_radii_deg.size\n",
    "    rf_array = np.zeros((number_of_rfs,3))\n",
    "    all_rfs = product(rf_radii_deg,np.concatenate((x_deg.ravel()[:,np.newaxis], y_deg.ravel()[:,np.newaxis],),axis=1))\n",
    "    \n",
    "    for ii,rf in enumerate(all_rfs):\n",
    "        rf_array[ii,:] = np.array([rf[0],rf[1][0],rf[1][1]])\n",
    "    \n",
    "    rf_table = pd.DataFrame(data=rf_array, columns=['deg_per_radius', 'x_deg', 'y_deg'])\n",
    "    \n",
    "    if pix_per_stim:\n",
    "        scale_factor = lambda row: row*pix_per_stim * (1./deg_per_stim) \n",
    "        rf_table['pix_per_radius'] = rf_table['deg_per_radius'].apply(scale_factor)\n",
    "        rf_table['x_pix'] = rf_table['x_deg'].apply(scale_factor)\n",
    "        rf_table['y_pix'] = rf_table['y_deg'].apply(scale_factor)\n",
    "    \n",
    "    return rf_table\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_table = make_rf_table(20, (.5, 2, 5), 2., pix_per_stim=3)\n",
    "rf_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_table.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = rf_table.plot(x='x_deg',y='y_deg',kind='scatter',)\n",
    "ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class receptive_fields():\n",
    "    def __init__(self,deg_per_stim, deg_per_radius, spacing):\n",
    "        '''\n",
    "        a class for organizing info about receptive fields, and generating rf filter.\n",
    "        \n",
    "        accepts the same inputs as \"make_rf_table\".\n",
    "        \n",
    "        stores rf_table as attribute.\n",
    "        \n",
    "        includes method \"make_rf_stack\" for generating stacks of rf filters at desired resolution\n",
    "    \n",
    "        \n",
    "        receptive_fields(self,deg_per_stim, deg_per_radius, spacing)\n",
    "            deg_per_stim   ~ scalar, determined by experiment\n",
    "            deg_per_radius ~ (min_rad, max_rad, num_rad) specify the range rf sizes\n",
    "            spacing        ~ scalar, spacing between rfs in deg\n",
    "\n",
    "        '''\n",
    "        \n",
    "        ##see \"make_rf_table\"\n",
    "        self.deg_per_stim = deg_per_stim\n",
    "        self.deg_per_radius = deg_per_radius\n",
    "        self.spacing = spacing\n",
    "        \n",
    "        ##the radius and location of each rf in degrees\n",
    "        self.rf_table = make_rf_table(deg_per_stim,deg_per_radius,spacing)\n",
    "        \n",
    "        ##the number of receptive fields\n",
    "        self.G = self.rf_table.shape[0]\n",
    "    \n",
    "\n",
    "    def make_rf_stack(self, pix_per_stim,min_pix_per_radius=None):\n",
    "        '''\n",
    "        make_rf_stack(self, pix_per_stim,min_pix_per_radius=None)\n",
    "        \n",
    "        construct stack of rfs at specified pixel resolution. if the number of pixels per radius for\n",
    "        an rf is too few at the desired resolution, return a 0-filter (i.e., a picture of nothing) for that\n",
    "        rf. prints a message whenever this happens.\n",
    "        \n",
    "    \n",
    "              pix_per_stim ~ scalar, determined by resolution of feature map\n",
    "        min_pix_per_radius ~ scalar, if pix_per_radius is below this level at the given pixel resolution, return all 0's\n",
    "        \n",
    "        returns G x S x S tensor of pictures of gaussian rf blobs.\n",
    "        '''\n",
    "        ##these are cheap to make, so just rebuild it with added pixel columns. that way it won't accidentally get saved\n",
    "        rf_table_pix = make_rf_table(self.deg_per_stim,self.deg_per_radius,self.spacing,pix_per_stim=pix_per_stim)\n",
    "        rf_sizes = rf_table_pix['deg_per_radius'].unique()\n",
    "        \n",
    "        too_small = np.array(map(lambda x: min_pix_per_radius > x, rf_table_pix['pix_per_radius'].unique())).astype('bool')\n",
    "        \n",
    "        if np.any(too_small):\n",
    "#             warn(\"some rf sizes are too small for resolution %d\" %(pix_per_stim))\n",
    "            print \"at pixel resolution %d the following rfs will default to 0: %s\" %(pix_per_stim,(rf_sizes[too_small],))\n",
    "                \n",
    "        rf_grid = np.zeros((self.G, pix_per_stim, pix_per_stim))\n",
    "        for cnt,rf in enumerate(rf_table_pix.iterrows()):\n",
    "            center = (rf[1]['x_pix'],rf[1]['y_pix'])\n",
    "            rad = rf[1]['pix_per_radius']\n",
    "            if not (rad < min_pix_per_radius): ##will fail if min_pix = None or if pix_per_radius is too small\n",
    "                rf_grid[cnt,:,:] = make_gaussian(center,rad,pix_per_stim) ##if rf too small, default to 0.\n",
    "                \n",
    "        return rf_grid\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = receptive_fields(20,(.5, 7,8),.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.rf_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_stack = rf.make_rf_stack(8,min_pix_per_radius=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(rf_stack[12400,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "class model_space():\n",
    "    '''\n",
    "    on init, commits to a feature_dictionary and a receptive_fields instance\n",
    "    records feature depth and resolutions and number of rf models but doesn't commit to \n",
    "    a particular set of stimuli\n",
    "    \n",
    "    knows how to generate and apply rf_stack to feature maps in the dictionary. \n",
    "    enforces the \"min_pix_per_radius\" constraint.\n",
    "    \n",
    "    shits out a 3D model_space_tensor.\n",
    "    \n",
    "    complains if dimensions/names of feature_dict doesn't match what it has already recorded.\n",
    "    \n",
    "    after training/model selection, these objects used to interpret models and generate predictions.\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, feature_dict, rf_instance, min_pix_per_radius=1, add_bias=False):\n",
    "        '''\n",
    "        model_space(feature_dict, rf_instance, min_pix_per_radius=1, add_bias=False)\n",
    "        feature_dictionary ~ dictionary of T x Di x Si x Si feature map tensors.\n",
    "                             T = integer, # of time-points (or trials, or sitmuli), constant for all features\n",
    "                             Di = feature depth, may vary across keys in dict.\n",
    "                             Si is feature map resolution in pixels. it may vary across keys.\n",
    "               rf_instance ~ instance of receptive_fields class\n",
    "          min_pix_per_stim ~ scalar, default = 1. don't consider rf's with fewer pixels than this.\n",
    "                             rf's will have to be downsampled to be applied to some feature map. if rf\n",
    "                             has fewer than this number of pixels, don't apply it to current feature map.\n",
    "                  add_bias ~ boolean, default = False. If true, add an additional \"bias\" feature of depth = 1, resolution = 0\n",
    "                             and index = -1. \n",
    "                 \n",
    "        constructs a feature_index dictionary. The dictionary has keys = feature_dictionary, and the \n",
    "        values are lists of indices into model_space_tensor.\n",
    "             \n",
    "        '''\n",
    "        self.min_pix_per_radius = min_pix_per_radius\n",
    "        self.receptive_fields = rf_instance\n",
    "        self.add_bias = add_bias\n",
    "        \n",
    "\n",
    "        \n",
    "        ##parse the feature dictionary to get feature depths, indices, resolutions\n",
    "        self.feature_depth = {}\n",
    "        self.feature_indices = {}\n",
    "        self.feature_resolutions = {}\n",
    "        idx = 0\n",
    "        for f_key in feature_dict.keys():\n",
    "            self.feature_depth[f_key] = feature_dict[f_key].shape[1]\n",
    "            self.feature_indices[f_key] = np.arange(idx,idx + self.feature_depth[f_key],step=1)\n",
    "            idx += self.feature_depth[f_key]\n",
    "            self.feature_resolutions[f_key] = feature_dict[f_key].shape[2]\n",
    "        \n",
    "        ##total feature depth\n",
    "        self.D = np.sum(self.feature_depth.values())\n",
    "        \n",
    "        ##update feature dictionaries if bias feature is wanted\n",
    "        if self.add_bias:\n",
    "            self.feature_depth['bias'] = 1\n",
    "            self.feature_resolutions['bias'] = 0\n",
    "            self.feature_indices['bias'] = -1\n",
    "            self.D += 1\n",
    "    \n",
    "    def normalize_model_space_tensor(self, mst,save=False):\n",
    "        '''\n",
    "        normalize_model_space_tensor(mst,save=False):\n",
    "        z-score each feature of each model in a model_space_tensor across time.\n",
    "        \n",
    "        if normalization_constants is already defined as an attribute, use them for z-scoring mst.\n",
    "        \n",
    "        otherwise, if save=True, calculate mean and standard deviation from mst provided and then apply\n",
    "        and store the calculated mean and stdev so that\n",
    "        self.normalization_constants[0]=mean\n",
    "        self.normalization_constants[0]=stdev.\n",
    "        \n",
    "        otherwise, complain and die\n",
    "        \n",
    "        '''\n",
    "      \n",
    "        if hasattr(self, 'normalization_constant'):\n",
    "            mn = self.normalization_constant[0]\n",
    "            stdev = self.normalization_constant[1]\n",
    "            if save:\n",
    "                warn('not saving because constants are already defined')\n",
    "        elif save: \n",
    "            mn = np.expand_dims(np.mean(mst,axis=1),axis=1)\n",
    "            stdev = np.expand_dims(np.std(mst,axis=1),axis=1)\n",
    "            self.normalization_constant = []\n",
    "            self.normalization_constant.append(mn)\n",
    "            self.normalization_constant.append(stdev)\n",
    "            print 'normalization constants have been saved'\n",
    "        else:\n",
    "            raise Exception('if you want to compute the mean and stdev from the current data, you have to commit to saving it as an attribute')\n",
    "        \n",
    "        ##z-score \n",
    "        mst -= mn\n",
    "        mst /= stdev\n",
    "        \n",
    "        ##convert nans to 0's for two reasons:\n",
    "        ##1. the bias feature\n",
    "        ##2. the feature/rf pairs where the feature map is too low-res for the rf to be meaningful\n",
    "        mst = np.nan_to_num(mst)\n",
    "        \n",
    "        print 'model_space_tensor has been z-scored'\n",
    "        return mst\n",
    "    \n",
    "        \n",
    "    \n",
    "    def construct_model_space_tensor(self,feature_dict,normalize=True):\n",
    "        '''\n",
    "        construct_model_tensor(feature_dictionary,normalize=True)\n",
    "        \n",
    "        checks feature_dict for appropriate keys/resolutions\n",
    "        \n",
    "        allocates memory for model_space_tensor\n",
    "        \n",
    "        loop over keys in feature dictionary\n",
    "        feature maps for each key have potentially unique resolution, so call make_rf_grid for each        \n",
    "        call theano function \"apply_rf_to_feature_maps\" for each map in dictionary\n",
    "        concatentates across features to form a model_space_tensor\n",
    "        \n",
    "        will normalize model space (z-score each rf/feature row across time) by default. note: you have to explicity\n",
    "        commit to normalization by running the normalize method on whatever you consider your training data to be and\n",
    "        setting save=True. until you've done that you won't be able to apply normalization.\n",
    "        \n",
    "        so, typically run\n",
    "        mst = model_space.construct_model_space_tensor(feature_dictionary,normalize=False)\n",
    "        mst = model_space.normalize_model_space_tensor(mst, save=True)\n",
    "        \n",
    "        then, any subsequent call to \"construct_model_space_tensor\" will normalize by default using saved constants.\n",
    "        \n",
    "        \n",
    "       returns\n",
    "        model_space_tensor ~ G x T x D tensor.\n",
    "                             D = sum(Di), total feature depth across all keys in the feature dictionary\n",
    "                             G = size of rf grid, or, the number of rf models we consider.\n",
    "                             each (D,T) plane give time-series for the D features after filtering by one of the G rf's.\n",
    "        '''\n",
    "        \n",
    "        ##check feature_dict for proper names/resolutions\n",
    "        key_list = self.feature_depth.keys()\n",
    "        for f_key in feature_dict.keys():\n",
    "            if f_key in key_list:\n",
    "                key_list.remove(f_key)\n",
    "            else:\n",
    "                raise ValueError(\"this feature dictionary doesn't match your model\")\n",
    "        \n",
    "        \n",
    "        ##determine T = number of time points / trials / stimuli . if T is not same for all keys freak out\n",
    "        all_Ts = map(lambda k: feature_dict[k].shape[0],feature_dict.keys())\n",
    "        if np.any(map(lambda x: all_Ts[0] != x, all_Ts)):\n",
    "            raise ValueError('temporal dimensiosn of feature map are not equal: %s' %(all_Ts,))\n",
    "        else:\n",
    "            self.T = all_Ts[0]\n",
    "        \n",
    "        ##allocate memory for model space\n",
    "        mst = np.zeros((self.receptive_fields.G, self.T, self.D)).astype('float32')\n",
    "        \n",
    "        ##loop over keys in feature dictionary\n",
    "        for feats in feature_dict.keys():\n",
    "            rf_stack = self.receptive_fields.make_rf_stack(self.feature_resolutions[feats],min_pix_per_radius=self.min_pix_per_radius).astype('float32')\n",
    "            mst[:,:,self.feature_indices[feats]] = apply_rf_to_feature_maps(rf_stack,feature_dict[feats])\n",
    "            \n",
    "        ##\n",
    "        if normalize:    \n",
    "            mst = self.normalize_model_space_tensor(mst,save=False)  ##save = false so won't work unless\n",
    "                                                                     ##you've already stored normalization_constants\n",
    "        \n",
    "        if self.add_bias:\n",
    "            mst[:,:,-1] = 1\n",
    "        \n",
    "        return mst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = 14\n",
    "fd = {}\n",
    "D = [1,2,3,4]\n",
    "S = [10,20,30,40]\n",
    "names = ['a','b','c','d']\n",
    "for i,n in enumerate(names):\n",
    "    fd[n] = np.random.rand(T,D[i],S[i],S[i]).astype('float32')\n",
    "ms = model_space(fd,rf,add_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ms.D\n",
    "print ms.feature_depth\n",
    "print ms.feature_indices\n",
    "print ms.feature_depth.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The logic of normalization.\n",
    "By default, we normalize all model_space_tensors. However, the model_space object will complain until you \n",
    "have explicitly saved a set of normalization constants. So, you have identify what you consider to be the\n",
    "\"training data\", generate a model_space_tensor from this data with \"normalize=False\", then \n",
    "normalize the resulting mst with \"save=True\".\n",
    "\n",
    "After that, any additional mst's generated by by the model_space object will be normalized using the saved\n",
    "means and standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mst = ms.construct_model_space_tensor(fd)\n",
    "##oops!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mst = ms.construct_model_space_tensor(fd,normalize=False)\n",
    "mst = ms.normalize_model_space_tensor(mst,save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(np.isnan(mst[0,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "T = 14\n",
    "new_fd = {}\n",
    "for i,n in enumerate(names):\n",
    "    new_fd[n] = np.random.rand(T,D[i],S[i],S[i]).astype('float32')\n",
    "\n",
    "new_mst = ms.construct_model_space_tensor(new_fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def prediction_menu(model_space_tensor, feature_weights, rf_indices=None):   \n",
    "#     '''\n",
    "#     prediction_menu(model_space_tensor, feature_weights, rf_indices=None)\n",
    "\n",
    "#     model_space_tensor ~ G x T x D   \n",
    "#        feature_weights ~ G x D x V, or 1 x D x V. If the latter, rf_indices = list of length = V.\n",
    " \n",
    "#      if rf_indices=None, returns G x T x V prediction menu tensor.\n",
    "#      otherwise,              returns T x V prediction menu tensor.\n",
    "#     '''\n",
    "#     G = model_space_tensor.shape[0] \n",
    "#     V = feature_weights.shape[2]\n",
    "#     if G != feature_weights.shape[0]:\n",
    "#         feature_weights = np.tile(feature_weights,[G,1,1])\n",
    "    \n",
    "    \n",
    "#     pmt = bigmult(model_space_tensor, feature_weights)\n",
    "    \n",
    "#     ##if rf_indices defined, select along G dimension and then diagonalize.\n",
    "#     if rf_indices != None:\n",
    "#         pmt = np.diagonal(pmt[rf_indices],axis1=0,axis2=2)\n",
    "    \n",
    "\n",
    "#     return pmt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V = 50\n",
    "feature_weights = np.random.rand(ms.receptive_fields.G, ms.D, V).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mst.shape\n",
    "print feature_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pmt = prediction_menu(mst.astype('float32'), feature_weights)\n",
    "print pmt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_feature_weights = np.zeros((ms.D,V))\n",
    "best_rfs = np.random.randint(0,high=ms.receptive_fields.G,size=V)\n",
    "for v in range(V):\n",
    "    best_feature_weights[:,v] = feature_weights[best_rfs[v],:,v]\n",
    "best_feature_weights = best_feature_weights.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_pmt = prediction_menu(mst, best_feature_weights[np.newaxis,:,:], rf_indices=best_rfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_pmt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print best_pmt[:,10]\n",
    "print pmt[best_rfs[10], :, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
