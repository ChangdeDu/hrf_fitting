{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use feature-weighted rf model on the crcns vim-1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from theano import tensor as tnsr\n",
    "from theano import function, scan\n",
    "from time import time\n",
    "from scipy.signal import convolve2d as conv2d\n",
    "from hrf_fitting.src.features import make_gaussian, construct_placement_grid\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "from hrf_fitting.src.feature_weighted_rf_models import apply_rf_to_feature_maps, bigmult, compute_grad,sq_diff_func\n",
    "from hrf_fitting.src.features import make_complex_gabor as gaborme\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: construct feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Df, Do = 8, 8  #Df = sp. freq. divisions, Do = orientations\n",
    "D = Df*Do + 1  # +1 for a bias dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load crcns stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stim_location = '/media/tnaselar/Data/crcns_datasets/vim-1/Stimuli.mat'\n",
    "crcns_stim_dict = loadmat(stim_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##need 'stimVal' and 'stimTrn'\n",
    "print crcns_stim_dict['stimVal'].shape\n",
    "print crcns_stim_dict['stimTrn'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##remember stim params\n",
    "Ttrn = crcns_stim_dict['stimTrn'].shape[0]\n",
    "Tval = crcns_stim_dict['stimVal'].shape[0]\n",
    "T = Ttrn+Tval\n",
    "native_stim_size = crcns_stim_dict['stimTrn'].shape[1]\n",
    "n_image_channels = 1 ##could be 3 for color images.\n",
    "stim_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(crcns_stim_dict['stimVal'][0,:,:],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### construct gabor wavelet stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##parameters for designing gabor feature maps\n",
    "##specify frequencies in cycles_per_pixel, use to determine size of prf.\n",
    "##should probably specify in cycles per deg.\n",
    "\n",
    "pixel_per_deg = 25*(stim_size/500.)    ##determined by experiment 34.751 = match/nonmatch exp.\n",
    "pixels_per_stimulus = stim_size ##det. by exp. 768 = match/nonmatch exp.\n",
    "cycles_per_deg = .15*np.logspace(0,1.7,num=Df)\n",
    "cycles_per_pixel = cycles_per_deg/pixel_per_deg  ##cyc/pix\n",
    "cycles_per_fwhm = 2.0\n",
    "fwhms_per_kernel = 2.0 ##determines how big the picture of the gabor will be.\n",
    "\n",
    "metrics = {'cycles per pixel':cycles_per_pixel,\n",
    "           'pixels per cycle': 1./cycles_per_pixel,\n",
    "           'cycles per stimulus': cycles_per_pixel*pixels_per_stimulus,\n",
    "           'cycles per deg.': cycles_per_deg,\n",
    "           'fwhm (pix)': np.clip(cycles_per_fwhm/cycles_per_pixel,0,pixels_per_stimulus),\n",
    "           'prf_size (deg)': np.clip(cycles_per_fwhm/cycles_per_pixel,0,pixels_per_stimulus)/pixel_per_deg/2.,\n",
    "           'n_pix': np.clip(fwhms_per_kernel*cycles_per_fwhm/cycles_per_pixel,0,pixels_per_stimulus)}\n",
    "\n",
    "fm = pd.DataFrame(metrics)\n",
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oris = np.linspace(0, 2*np.pi, num=Do, endpoint=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### generate feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##--make a theano function for this\n",
    "stim_tnsr = tnsr.tensor4('stim_tnsr')  ##T x n_image_channels x stim_size x stim_size\n",
    "real_filter_stack_tnsr = tnsr.tensor4('real_feature_map_tnsr') ##D x n_image_channels x stim_size x stim_size. complex\n",
    "imag_filter_stack_tnsr = tnsr.tensor4('imag_feature_map_tnsr') ##D x n_image_channels x stim_size x stim_size. complex\n",
    "filter_stack_tnsr_shape = (1, n_image_channels,stim_size,stim_size)\n",
    "real_feature_map_tnsr = tnsr.nnet.conv2d(stim_tnsr,\n",
    "                                 real_filter_stack_tnsr,\n",
    "                                 image_shape = (1,n_image_channels,stim_size,stim_size),\n",
    "                                 filter_shape = filter_stack_tnsr_shape,\n",
    "                                 border_mode = 'full')  ##produces T x D x stim_size x stim_size maps\n",
    "imag_feature_map_tnsr = tnsr.nnet.conv2d(stim_tnsr,\n",
    "                                 imag_filter_stack_tnsr,\n",
    "                                 image_shape = (1,n_image_channels,stim_size,stim_size),\n",
    "                                 filter_shape = filter_stack_tnsr_shape,\n",
    "                                 border_mode = 'full')  ##produces T x D x stim_size x stim_size maps\n",
    "\n",
    "##for filtering with complex gabors, we need an operation for squaring/summing real/imag parts\n",
    "\n",
    "abs_value = tnsr.sqrt(tnsr.sqr(real_feature_map_tnsr) + tnsr.sqr(imag_feature_map_tnsr))\n",
    "##functionize feature mapping\n",
    "make_feature_maps = function(inputs = [stim_tnsr,real_filter_stack_tnsr,imag_filter_stack_tnsr],\n",
    "                             outputs = abs_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##create filter stack, but separate real/imag parts because theano doesn't like complex numbers\n",
    "##here we leave Dth filter at zero because later we will add a \"bias\" feature of all 1's.\n",
    "filter_channels = 2\n",
    "filter_stack = np.zeros((D, filter_channels, stim_size, stim_size)).astype('float32')\n",
    "f_counter = 0\n",
    "feature_map_params = []\n",
    "for df in range(Df):\n",
    "    for do in range(Do):\n",
    "        ori = oris[do]\n",
    "        center = (0,0)\n",
    "        freq = fm.loc[df,'cycles per stimulus']\n",
    "        fwhm = fm.loc[df,'fwhm (pix)']\n",
    "        n_pix = stim_size\n",
    "        feature_map_params.append( (ori,freq,fwhm,n_pix) )\n",
    "        tmp_filter = gaborme(freq,ori,center,fwhm,n_pix)\n",
    "        filter_stack[f_counter,0,:,:] = np.real(tmp_filter).astype('float32')\n",
    "        filter_stack[f_counter,1,:,:] = np.imag(tmp_filter).astype('float32')\n",
    "        f_counter += 1\n",
    "##show imag. part of some filter    \n",
    "plt.imshow(filter_stack[-2,1,:,:],cmap='gray')\n",
    "print filter_stack.shape\n",
    "\n",
    "feature_map_params = pd.DataFrame(data=feature_map_params,columns=['ori','freq','fwhm','n_pix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_map_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_maps = np.zeros((T,D,stim_size,stim_size))\n",
    "stimuli = np.concatenate((crcns_stim_dict['stimVal'],crcns_stim_dict['stimTrn']),axis=0)\n",
    "for d in range(Df*Do):\n",
    "    start = time()\n",
    "    for t in range(T):\n",
    "        \n",
    "        this_stim = np.array(Image.fromarray(stimuli[t,:,:]).resize((stim_size,stim_size))).astype('float32')\n",
    "        this_stim = this_stim[np.newaxis,np.newaxis,:,:]\n",
    "        tmp_feature_map = make_feature_maps(this_stim,\n",
    "                                            np.reshape(filter_stack[d,0,:,:], (1,n_image_channels,stim_size,stim_size)),\n",
    "                                            np.reshape(filter_stack[d,1,:,:], (1,n_image_channels,stim_size,stim_size)))\n",
    "    \n",
    "        ##crop because convolution\n",
    "        new_size = tmp_feature_map.shape[2]\n",
    "        crop_start = np.round((new_size-stim_size)/2.).astype('int')\n",
    "        crop_stop = crop_start+stim_size\n",
    "        feature_maps[t,d,:,:] = tmp_feature_map[:, :, crop_start:crop_stop, crop_start:crop_stop]\n",
    "    print 'feature %d took %0.3f' %(d,time()-start)\n",
    "print feature_maps.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "3+(3*96)+(3*256)+(384*2)+(256*2)+(2*4096)+(2*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(stimuli[-1,:,:])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(feature_maps[-1,15,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##force float 32 explicitly\n",
    "feature_maps = feature_maps.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: construct model_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create receptive field model stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Gx,Gy,Gw = 16,16,Df\n",
    "G = Gx*Gy*Gw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def space_time_kernel(center, fwhm, n_pix, time_kernel):\n",
    "    '''\n",
    "    a separable space-time kernel.\n",
    "    space kernel is gaussian\n",
    "    time kernel is an array of length T\n",
    "    returns a 3-D volume that is (n_pix,n_pix,T)\n",
    "    slice it to see what it does.\n",
    "    '''\n",
    "    space_kernel = np.atleast_3d(make_gaussian(center,fwhm,n_pix))\n",
    "    return time_kernel*space_kernel\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##dumb grid\n",
    "##create filter stack, but separate real/imag parts because theano doesn't like complex numbers\n",
    "g_counter = 0\n",
    "half_stim_size = np.round(stim_size/2.).astype('int')\n",
    "g_rows, g_cols = construct_placement_grid([-half_stim_size,half_stim_size,-half_stim_size,half_stim_size],np.round(stim_size/Gx).astype('int'))\n",
    "rf_stack = np.zeros((Gx*Gy*Gw, stim_size, stim_size)).astype('float32')\n",
    "rf_params = []\n",
    "for gw in fm['fwhm (pix)']:\n",
    "    for gx,gy in zip(g_rows.ravel(),g_cols.ravel()):\n",
    "            center = (gx,gy)\n",
    "            fwhm = gw\n",
    "            rf_stack[g_counter,:,:] = np.squeeze(space_time_kernel(center, fwhm, stim_size, 1)).astype('float32')\n",
    "            g_counter += 1\n",
    "            rf_params.append( (gx,gy,fwhm) )\n",
    "rf_params = pd.DataFrame(data=rf_params,columns=['x','y','fwhm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(rf_stack[17+8,:,:])\n",
    "print rf_stack.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply rf stack to feature maps to construct model_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_space = np.zeros((G,T,D))\n",
    "for t in range(T):\n",
    "    start = time()\n",
    "    model_space[:,np.newaxis,t,:] = apply_rf_to_feature_maps(rf_stack, feature_maps[t,np.newaxis,:,:])\n",
    "    if (t % 100) == 0:\n",
    "        print time()-start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalize the model space. THIS IS ABSOLUTELY ESSENTIAL!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### normalize model space and add a column of 1's to each model: \n",
    "model_space = model_space - np.expand_dims(np.mean(model_space,axis=1),axis=1)\n",
    "model_space = model_space / np.expand_dims(np.std(model_space,axis=1),axis=1)\n",
    "model_space[:,:,-1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##clear up some memory\n",
    "feature_maps = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_space = model_space.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: train model on real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load voxel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voxel_file = '/media/tnaselar/Data/crcns_datasets/vim-1/EstimatedResponses.mat'\n",
    "crcns_voxel_data = h5py.File(voxel_file)\n",
    "crcns_voxel_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vs1 = crcns_voxel_data['dataTrnS1'].shape[1]\n",
    "print Vs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove nans, becuase this data-set has some. otherwise even one nan will infect gradient for every voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voxel_data = np.concatenate((crcns_voxel_data['dataValS1'],crcns_voxel_data['dataTrnS1']),axis=0).astype('float32')\n",
    "no_nan = np.isnan(crcns_voxel_data['dataTrnS1']).sum(axis=0) == 0\n",
    "voxel_data = voxel_data[:,no_nan]\n",
    "print voxel_data.shape\n",
    "V = voxel_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.sum(np.isnan(voxel_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training / testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_fwrf_model(model_space, voxel_data,initial_feature_weights,\n",
    "                     early_stop_fraction = 0.2,\n",
    "                     max_iters=100,\n",
    "                     mini_batch_size = 0.1,\n",
    "                     learning_rate=10**(-5),\n",
    "                     voxel_binsize=100,\n",
    "                     rf_grid_binsize = 200,\n",
    "                     report_every = 10):\n",
    "\n",
    "    ##basic dimenisions\n",
    "    G,T,D = model_space.shape ##G = size of rf grid, T = number of trials (timepoints), D = number of feature weights\n",
    "    _,V = voxel_data.shape ##V = number of voxels\n",
    "\n",
    "    ##chunk up the voxels\n",
    "    trnIdx = np.arange(0,T)\n",
    "    early_stop_num = np.round(len(trnIdx)*early_stop_fraction).astype('int')\n",
    "    voxel_bin_num = max(2,np.round(V/voxel_binsize))\n",
    "    voxel_bins = np.linspace(0,V-1,num=voxel_bin_num,endpoint=True)\n",
    "\n",
    "    ##chunk up the rf grids\n",
    "    gdx = np.arange(0,G)\n",
    "    rf_bin_num = np.round(G/rf_grid_binsize)\n",
    "    rf_bins = np.linspace(0,G-1,num=rf_bin_num,endpoint=True)\n",
    "\n",
    "    ##clock the whole function execution.\n",
    "    big_start = time()\n",
    "            \n",
    "    ##prepare indices for data split\n",
    "    perm_dx = np.random.permutation(trnIdx)\n",
    "    validation_idx = perm_dx[0:early_stop_num]\n",
    "    training_idx = perm_dx[early_stop_num:]\n",
    "    validation_idx = np.atleast_2d(np.sort(validation_idx).astype('int')) ##1 x val_idx.shape[1]\n",
    "    training_idx = np.atleast_2d(np.sort(training_idx).astype('int')) ##1 x trn_idx.shape[1]\n",
    "    \n",
    "    ##for storing the final model for each voxel\n",
    "    final_rf = np.zeros(V).astype('int')\n",
    "    final_feature_weights = np.zeros((D,V)).astype('float32')\n",
    "    final_validation_loss = np.inf*np.ones(V)\n",
    "    \n",
    "    ####store error history of best rf model for each voxel\n",
    "    best_error_history = np.zeros((max_iters,V))\n",
    "    \n",
    "    ##iterate over batches of voxels\n",
    "    for v in range(len(voxel_bins)-1):\n",
    "        \n",
    "        ##indices for current batch of voxels\n",
    "        v_idx = np.atleast_2d(np.arange(voxel_bins[v], voxel_bins[v+1]).astype('int')) ##1 x v_idx.shape[1]\n",
    "        this_vox_batch_size = v_idx.shape[1]\n",
    "        print '--------------voxels from %d to %d' %(v_idx[0,0],v_idx[0,-1])\n",
    "        \n",
    "        ##get data for these voxels\n",
    "        this_trn_voxel_data = voxel_data[training_idx.T, v_idx]\n",
    "        this_val_voxel_data = voxel_data[validation_idx.T, v_idx]\n",
    "        print this_trn_voxel_data.shape\n",
    "        print this_val_voxel_data.shape\n",
    "        \n",
    "        \n",
    "        ##iterate over batches of rf models\n",
    "        for g in range(len(rf_bins)-1):\n",
    "            \n",
    "            ##indices for current batch of rf models\n",
    "            rf_idx = np.atleast_2d(np.arange(rf_bins[g], rf_bins[g+1]).astype('int')) ##1 x rf_idx.shape[1]\n",
    "            this_rf_batch_size = rf_idx.shape[1]\n",
    "            print '--------candiate rf models %d to %d' %(rf_idx[0,0],rf_idx[0,-1])\n",
    "            \n",
    "            ##slice model space for this batch of models / this batch of voxels\n",
    "            this_trn_model_space = model_space[rf_idx.T,training_idx,:]\n",
    "            this_val_model_space = model_space[rf_idx.T,validation_idx,:]\n",
    "            print this_trn_model_space.shape\n",
    "            print this_val_model_space.shape\n",
    "#             1/0\n",
    "\n",
    "            ##initialize best and current loss containers for this batch of voxels/models\n",
    "            best_validation_loss = Inf*np.ones((this_rf_batch_size,this_vox_batch_size)) #rf_chunk x voxel_chunk\n",
    "            this_validation_loss = np.zeros(best_validation_loss.shape)\n",
    "            \n",
    "            ##initialize best and current weight containers for this batch of voxels/models\n",
    "            best_feature_weights = initial_feature_weights[rf_idx.flatten(),:,:]\n",
    "            best_feature_weights = best_feature_weights[:,:,v_idx.flatten()]\n",
    "            feature_weights = copy(best_feature_weights)\n",
    "            \n",
    "            \n",
    "            ##initialize reports. so you can waste an entire afternoon watching your models train.\n",
    "            iter_error = np.zeros((max_iters, this_vox_batch_size))\n",
    "            bestie_change = np.zeros(max_iters)\n",
    "            old_besties = np.zeros(this_vox_batch_size)\n",
    "            \n",
    "            ##initialize counters\n",
    "            iters = 0\n",
    "            start = time()\n",
    "                        \n",
    "            ##take gradient steps for a fixed number of iterations\n",
    "            while (iters < max_iters):\n",
    "                \n",
    "                ##gradient: put a loop here over chunks of rf models to save on memory\n",
    "                d_loss_wrt_params = compute_grad(this_trn_voxel_data,\n",
    "                                                 this_trn_model_space,\n",
    "                                                 feature_weights)\n",
    "                \n",
    "                \n",
    "                ##update feature weights\n",
    "                feature_weights -= learning_rate * d_loss_wrt_params\n",
    "                \n",
    "                ##predictions with updated feature weights\n",
    "                prediction_menu = bigmult(this_val_model_space,\n",
    "                                          feature_weights)\n",
    "\n",
    "                ##updated loss\n",
    "                this_validation_loss = sq_diff_func(this_val_voxel_data,\n",
    "                                                    prediction_menu)\n",
    "                \n",
    "                ##if new loss minimum, save as best\n",
    "                improved = this_validation_loss < best_validation_loss  ##rf batch x voxel batch\n",
    "                imp = np.sum(improved)\n",
    "                for ii in range(this_rf_batch_size):\n",
    "                    best_validation_loss[ii,improved[ii,:]] = copy(this_validation_loss[ii,improved[ii,:]])\n",
    "                    best_feature_weights[ii,:,improved[ii,:]] = copy(feature_weights[ii,:,improved[ii,:]])\n",
    "                \n",
    "                ##reporting business\n",
    "                iter_error[iters,:]  = np.min(this_validation_loss,axis=0)\n",
    "                besties = np.argmin(this_validation_loss,axis=0)\n",
    "                bestie_change[iters] = np.sum(besties - old_besties)\n",
    "                old_besties = copy(besties)\n",
    "                if iters % report_every == 0:\n",
    "                    print '-------'\n",
    "                    print 'errors: %f' %(np.nanmean(iter_error[iters,:]))\n",
    "                    print 'change in best rf: %f' %(bestie_change[iters])\n",
    "                    print 'norm of feature weights: %f' %(np.sqrt(np.sum(feature_weights*feature_weights)))\n",
    "                    print 'improvements: %d' %(imp)\n",
    "                    print time()-start\n",
    "                    start = time()\n",
    "                \n",
    "                ##update iteration\n",
    "                iters += 1\n",
    "            \n",
    "            ##if the best of this batch of models has achieved new loss minimum, save it.\n",
    "            for ii in range(this_vox_batch_size):\n",
    "                best_of_batch_rf = np.argmin(best_validation_loss[:,ii]) ##index into current rf batch\n",
    "                this_voxel = v_idx.flatten()[ii] ##total voxel index \n",
    "                if best_validation_loss[best_of_batch_rf,ii] < final_validation_loss[this_voxel]:\n",
    "                    final_validation_loss[this_voxel] = copy(best_validation_loss[best_of_batch_rf,ii])\n",
    "                    final_feature_weights[:,this_voxel] = copy(best_feature_weights[best_of_batch_rf,:,ii])\n",
    "                    final_rf[this_voxel] = rf_idx[0,best_of_batch_rf]\n",
    "                    best_error_history[:,this_voxel] = copy(iter_error[:,ii])\n",
    "\n",
    "    print time()-big_start\n",
    "    return final_validation_loss,final_feature_weights,final_rf,best_error_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvox=-1\n",
    "trnIdx = np.arange(Tval,T)\n",
    "valIdx = np.arange(0,Tval)\n",
    "trn_voxel_data = voxel_data[trnIdx,0:nvox]\n",
    "trn_model_space = model_space[:,trnIdx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fvl,ffw,frf,beh = train_fwrf_model(trn_model_space,\n",
    "                 trn_voxel_data,\n",
    "                 np.zeros((G,D,V)).astype('float32'),\n",
    "                 voxel_binsize = 1000,\n",
    "                 rf_grid_binsize=40,\n",
    "                 learning_rate=10**(-5.0),\n",
    "                 max_iters = 50,\n",
    "                 early_stop_fraction=0.2,\n",
    "                 report_every = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.plot(beh-beh[0,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(beh[:,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.min(beh[:,-2])\n",
    "print fvl[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.hist(beh[0,:]-np.min(beh,axis=0),100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pdb off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.hist(frf,2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.sum(rf_stack[frf,:,:], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.bincount(frf,minlength=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(rf_stack[1904,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4:  validation and model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "val_voxel_data = voxel_data[valIdx,0:nvox]\n",
    "val_model_space = model_space[:,valIdx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = np.zeros((Tval,nvox))\n",
    "for v in range(nvox):\n",
    "    pred[:,v] = np.squeeze(bigmult(val_model_space[np.newaxis,frf[v],:,:],\n",
    "                                   ffw[np.newaxis,:,v, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(pred,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_cc = []\n",
    "for v in range(nvox):\n",
    "    cc = pearsonr(val_voxel_data[:,v],pred[:,v])\n",
    "    if not np.isnan(cc[0]):\n",
    "        val_cc.append(cc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.hist(val_cc,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
