{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use feature-weighted rf model on the crcns vim-1 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.sandbox.cuda): Failed to compile cuda_ndarray.cu: libcublas.so.7.5: cannot open shared object file: No such file or directory\n",
      "ERROR:theano.sandbox.cuda:Failed to compile cuda_ndarray.cu: libcublas.so.7.5: cannot open shared object file: No such file or directory\n",
      "WARNING (theano.sandbox.cuda): CUDA is installed, but device gpu is not available  (error: cuda unavilable)\n",
      "WARNING:theano.sandbox.cuda:CUDA is installed, but device gpu is not available  (error: cuda unavilable)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from time import time\n",
    "from glob import glob\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "from scipy.stats import pearsonr\n",
    "from hrf_fitting.src.feature_weighted_rf_models import make_rf_table,receptive_fields, model_space, prediction_menu, bigmult\n",
    "from hrf_fitting.src.feature_weighted_rf_models import train_fwrf_model\n",
    "from hrf_fitting.src.gabor_feature_dictionaries import gabor_feature_maps\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Load crcns stimuli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load crcns stimuli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##known stimulus parameters\n",
    "Ttrn = 1750\n",
    "Tval = 120\n",
    "S = 500\n",
    "T = Ttrn+Tval\n",
    "train_stim_files = glob('/media/tnaselar/Data/crcns_datasets/vim-1/Stimuli_Trn_FullRes*.mat')\n",
    "val_stim_file = '/media/tnaselar/Data/crcns_datasets/vim-1/Stimuli_Val_FullRes.mat'\n",
    "n_image_channels = 1 ##could be 3 for color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##allocate memory for stim\n",
    "training_stim = np.zeros((Ttrn,S,S),dtype='float32')\n",
    "\n",
    "##load training stim\n",
    "cnt = 0\n",
    "for sl in sorted(train_stim_files):\n",
    "    this_h5 = h5py.File(sl,'r')\n",
    "    this_train_stim = this_h5['stimTrn']\n",
    "    this_num_stim = this_train_stim.shape[-1]\n",
    "    training_stim[cnt:cnt+this_num_stim,:,:] = np.transpose(this_train_stim[:],[2,1,0])\n",
    "    cnt += this_num_stim\n",
    "    this_h5.close()\n",
    "    \n",
    "##load validation stim\n",
    "val_h5 = h5py.File(val_stim_file,'r')\n",
    "validation_stim = np.transpose(val_h5['stimVal'][:],[2,1,0])\n",
    "val_h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(validation_stim[0,:,:],cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(training_stim[-1,:,:],cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: construct feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_orientations = 8\n",
    "deg_per_stimulus = 20\n",
    "lowest_sp_freq = .25 ##cyc/deg\n",
    "highest_sp_freq = 6.25\n",
    "num_sp_freq = 8\n",
    "pix_per_cycle = 4#2.13333333\n",
    "complex_cell = True\n",
    "\n",
    "print 'D = total number of features = %d' %(n_orientations * num_sp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### construct gabor wavelet stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gfm = gabor_feature_maps(n_orientations,\n",
    "                         deg_per_stimulus,\n",
    "                         (lowest_sp_freq,highest_sp_freq,num_sp_freq),\n",
    "                         pix_per_cycle=pix_per_cycle,complex_cell=complex_cell,\n",
    "                         diams_per_filter = 4,\n",
    "                        cycles_per_radius = 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gfm.gbr_table.head(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gfm.filter_stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### see one of the gabors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o =  ##choose an orientation\n",
    "plt.imshow(np.imag(gfm.filter_stack[o,0,:,:]),cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: receptive fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deg_per_radius = (.5, 8, 8) ##rf sizes in degrees (smallest, largest, number of sizes)\n",
    "spacing = 1. ##spacing between rf's in degrees\n",
    "rf = receptive_fields(deg_per_stimulus,deg_per_radius,spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf.rf_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'G = number of rf models = %d' %(rf.rf_table.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### instantiate model space object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_stim[0,np.newaxis,np.newaxis,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##construct the model space\n",
    "init_feat_dict = gfm.create_feature_maps(training_stim[0,np.newaxis,np.newaxis,:,:])\n",
    "ms = model_space(init_feat_dict, rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ms.feature_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### construct training/validation model space tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##loop over training stimuli because feature maps for all training stim. > 48Gb\n",
    "training_mst = np.zeros((ms.receptive_fields.G, Ttrn, ms.D)).astype('float32')\n",
    "\n",
    "num_chunks = 2\n",
    "stim_dx = np.linspace(0,T-1,num=num_chunks+1, endpoint=True,dtype='int')\n",
    "\n",
    "cnt = 0\n",
    "for t in stim_dx[1:]:\n",
    "    this_training_feature_dict = gfm.create_feature_maps(training_stim[cnt:cnt+t,np.newaxis,:,:])\n",
    "    training_mst[:,cnt:cnt+t,:] = ms.construct_model_space_tensor(this_training_feature_dict,normalize=False)\n",
    "    cnt += t\n",
    "\n",
    "##clear up memory\n",
    "this_training_feature_dict = []\n",
    "\n",
    "##normalize and save normalization constants\n",
    "training_mst = ms.normalize_model_space_tensor(training_mst, save=True)\n",
    "\n",
    "\n",
    "##should work in one shot for because not too big\n",
    "val_feature_dict = gfm.create_feature_maps(validation_stim[:,np.newaxis,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: load and package crcns voxel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voxel_file = '/media/tnaselar/Data/crcns_datasets/vim-1/EstimatedResponses.mat'\n",
    "crcns_voxel_data = h5py.File(voxel_file,'r')\n",
    "crcns_voxel_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove nans, becuase this data-set has some. otherwise even one nan will infect gradient for every voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voxel_data = np.concatenate((crcns_voxel_data['dataValS1'],crcns_voxel_data['dataTrnS1']),axis=0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(voxel_data[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_nan = np.isnan(voxel_data).sum(axis=0) == 0 ##<<pull voxels with nans \n",
    "voxel_data = voxel_data[:,no_nan]\n",
    "print voxel_data.shape\n",
    "V = voxel_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crcns_voxel_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get training/validation views on voxel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nvox=V\n",
    "trnIdx = np.arange(Tval,T)\n",
    "valIdx = np.arange(0,Tval)\n",
    "trn_voxel_data = voxel_data[trnIdx,0:nvox]\n",
    "val_voxel_data = voxel_data[valIdx,0:nvox]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4.5: Make a fake voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fake_rf = 100\n",
    "fake_weights = np.random.rand(1,ms.D,1).astype('float32')\n",
    "trn_voxel_data[:,0] = np.squeeze(bigmult(training_mst[np.newaxis,fake_rf,:,:],\n",
    "                                   fake_weights))\n",
    "val_voxel_data[:,0] = np.squeeze(bigmult(validation_mst[np.newaxis,fake_rf,:,:],\n",
    "                                   fake_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_mst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: run that shit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### initialize the feature weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initial_feature_weights = np.zeros((ms.receptive_fields.G,ms.D,nvox),dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fvl,ffw,frf,beh = train_fwrf_model(training_mst,\n",
    "                 trn_voxel_data,\n",
    "                 initial_feature_weights='zeros',\n",
    "                 voxel_binsize = nvox,\n",
    "                 rf_grid_binsize=10,\n",
    "                 learning_rate=10**(-5.),\n",
    "                 max_iters = 50,\n",
    "                 early_stop_fraction=0.2,\n",
    "                 report_every = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss histories, all voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_=plt.plot(beh[:,1:]-beh[0,1:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### view loss history for a few voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.plot(beh[:,slice(0,-1,200)]-beh[0,slice(0,-1,200)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##loss in \"final_validation_loss\" = last point of \"best_error_history\"\n",
    "print np.min(beh[:,-2])\n",
    "print fvl[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diff between first and last point of loss history, all voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.hist(beh[0,1:]-np.min(beh[:,1:],axis=0),100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: model analysis and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### histogram of rf models selected for each voxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_=plt.hist(frf,ms.receptive_fields.G)\n",
    "plt.xlabel('smaller-->bigger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sum of all selected rfs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.sum(ms.receptive_fields.make_rf_stack(64, min_pix_per_radius=1)[frf,:,:], axis=0), cmap='hot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prediction accuracy for all voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##generate predictions\n",
    "# pred = prediction_menu(val_mst, ffw[np.newaxis,:,:], rf_indices = frf) ##<<too big, choked. \n",
    "\n",
    "\n",
    "##generate predictions one voxel at a time\n",
    "pred = np.zeros((Tval,nvox))\n",
    "for v in range(nvox-1):  ##<<some kind of bug in training function, last voxel getting skipped.\n",
    "    pred[:,v] = np.squeeze(bigmult(validation_mst[np.newaxis,frf[v],:,:],\n",
    "                                   ffw[np.newaxis,:,v, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_mst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##get correlation = prediction accuracy\n",
    "val_cc = []  \n",
    "for v in range(nvox-1): \n",
    "    cc = pearsonr(val_voxel_data[:,v],pred[:,v])\n",
    "    if not np.isnan(cc[0]):\n",
    "        val_cc.append(cc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##histogram of prediction accuracy, all voxels\n",
    "_=plt.hist(val_cc,100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
